<div align="center">

# Comercio Digital Ventas & Ingresos en medios anuncios digitales   ETL Pipeline
### Arquitectura Medallion en Azure Databricks

[![Databricks](https://img.shields.io/badge/Databricks-FF3621?style=for-the-badge&logo=databricks&logoColor=white)](https://databricks.com/)
[![Azure](https://img.shields.io/badge/Azure-0078D4?style=for-the-badge&logo=microsoft-azure&logoColor=white)](https://azure.microsoft.com/)
[![PySpark](https://img.shields.io/badge/PySpark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white)](https://spark.apache.org/)
[![Delta Lake](https://img.shields.io/badge/Delta_Lake-00ADD8?style=for-the-badge&logo=delta&logoColor=white)](https://delta.io/)
[![Databricks Dashboards](https://img.shields.io/badge/Databricks Dashboards-F2C81?style=for-the-badge&logo=databricks&logoColor=black)](https://databricks.com/)
[![CI/CD](https://img.shields.io/badge/CI%2FCD-GitHub_Actions-2088FF?style=for-the-badge&logo=github-actions&logoColor=white)](https://github.com/features/actions)

*Pipeline de Analisis de Ventas y/o Ingresos en Medios Digitales desde en punto de Ventas comercio digital  con arquitectura de tres capas y despliegue continuo*

</div>

---

## ğŸ¯ DescripciÃ³n

Pipeline ETL enterprise-grade que extrae desde un origen de base de datos relacional en nube azure sqldatabase y transforma para realizar una analisis de Ventas y/o Ingresos en los Medios digitales musicales a travez de los distintos productos (Anuncios, publicidad en medios digitales como diarios digital y/o medios musicales)  **Arquitectura Medallion** (Bronze-Silver-Gold) en Azure Databricks con **CI/CD completo** y **Delta Lake** para garantizar consistencia ACID.

### âœ¨ CaracterÃ­sticas Principales

- ğŸ”„ **ETL Automatizado** - Pipeline completo con despliegue automÃ¡tico via GitHub Actions
- ğŸ—ï¸ **Arquitectura Medallion** - SeparaciÃ³n clara de capas Bronze â†’ Silver â†’ Gold
- ğŸ“Š **Modelo Dimensional** - Star Schema optimizado para anÃ¡lisis de negocio
- ğŸš€ **CI/CD Integrado** - Deploy automÃ¡tico en cada push a master
- ğŸ“ˆ **Databricks Dashboards** - VisualizaciÃ³n
- âš¡ **Delta Lake** - ACID transactions y time travel capabilities
- ğŸ”” **Monitoreo** - Notificaciones automÃ¡ticas y logs detallados

---

## ğŸ›ï¸ Arquitectura

### Flujo de Datos

```
ğŸ“„ Enpoint Azure sql database (db-datacom)
    â†“
ğŸ¥‰ Bronze Layer (Ingesta sin transformaciÃ³n)
    â†“
ğŸ¥ˆ Silver Layer (Limpieza + Modelo Dimensional)
    â†“
ğŸ¥‡ Gold Layer (Tabla final desnormalizada Analisis comercio DÃ­gital)
    â†“
ğŸ“Š Databricks Dashboards (VisualizaciÃ³n)
```

![image alt]https://github.com/JohanSV83/CICDIGICOM01/blob/a57494cf4cceed8cc3ab174b36a6b5357ee6e94f/Seguridad/Arquitectura.jpg


### ğŸ“¦ Capas del Pipeline

<table>
<tr>
<td width="33%" valign="top">

#### ğŸ¥‰ Bronze Layer
**PropÃ³sito**: Zona de aterrizaje

**Tablas**: 
- `atalog_comercial.bronze.cliente` 
- `catalog_comercial.bronze.cobertura` 
- `catalog_comercial.bronze.medio`
- `catalog_comercial.bronze.tipo_medio` 
- `catalog_comercial.bronze.producto`
- `catalog_comercial.bronze.tipo_producto`
- `catalog_comercial.bronze.ejecutivo`
- `catalog_comercial.bronze.ejecutivo_digital`
- `catalog_comercial.bronze.grupo_laboral`
- `catalog_comercial.bronze.contrato`
- `catalog_comercial.bronze.condicion_pago`
- `catalog_comercial.bronze.forma_factura`
- `catalog_comercial.bronze.tipo_venta`
- `catalog_comercial.bronze.pedido`
- `catalog_comercial.bronze.pedido_detalle`
- `catalog_comercial.bronze.orden`
- `catalog_comercial.bronze.orden_detalle`

**CaracterÃ­sticas**:
- âœ… Datos tal como vienen de origen
- âœ… Timestamp de ingesta
- âœ… PreservaciÃ³n histÃ³rica
- âœ… Sin validaciones

</td>
<td width="33%" valign="top">

#### ğŸ¥ˆ Silver Layer
**PropÃ³sito**: Modelo dimensional

**Tablas**:
- `catalog_comercial.silver.cliente`
- `catalog_comercial.silver.ejecutivo`
- `catalog_comercial.silver.ejecutivo_digital`
- `catalog_comercial.silver.tipo_medio`
- `catalog_comercial.silver.medio`
- `catalog_comercial.silver.producto`
- `catalog_comercial.silver.tipo_producto`
- `catalog_comercial.silver.grupo_laboral`
- `catalog_comercial.silver.tipo_venta`
- `catalog_comercial.silver.cobertura`
- `catalog_comercial.silver.condicion_pago`
- `catalog_comercial.silver.contrato`
- `catalog_comercial.silver.forma_factura`
- `catalog_comercial.silver.pedido`
- `catalog_comercial.silver.pedido_detalle`
- `catalog_comercial.silver.orden`
- `catalog_comercial.silver.orden_detalle`


**CaracterÃ­sticas**:
- âœ… Star Schema
- âœ… Datos normalizados
- âœ… Validaciones completas

</td>
<td width="33%" valign="top">

#### ğŸ¥‡ Gold Layer
**PropÃ³sito**: Analytics-Comercial Digital

**Tablas**:
- `catalog_comercial.golden.ordenes_digitales`        : tabla desnormalizada para analisis de Ventas de Ventas / Ingresos en medios digitales (Anuncios, banner, video, display, content, contenido, etc)


**CaracterÃ­sticas**:
- âœ… Pre-agregados
- âœ… Optimizado para BI
- âœ… Performance mÃ¡ximo
- âœ… Actualizaciones automÃ¡ticas

</td>
</tr>
</table>

---

## ğŸ“ Estructura del Proyecto

```
etl-apple/
â”‚
â”œâ”€â”€ ğŸ“‚ .github/
â”‚   â””â”€â”€ ğŸ“‚ workflows/
â”‚       â””â”€â”€ ğŸ“„ cicd_dev_to_prod.yml   # Pipeline CI/CD deploy a certification workspace databricks
â”œâ”€â”€ ğŸ“‚ procesos/
â”‚   â”œâ”€â”€ ğŸ Preparacion_com_ambiente.ipynb           # Bronze layer
â”‚   â”œâ”€â”€ ğŸ ingestion_com_data.ipynb              # Bronze Layer
â”‚   â”œâ”€â”€ ğŸ cleaning_com_data.ipynb          # Silver Layer
â”‚   â”œâ”€â”€ ğŸ transform_com_data.ipynb       # Silver Layer
â”‚   â””â”€â”€ ğŸ kpi_com_data.ipynb               # Gold Layer
â”œâ”€â”€ ğŸ“‚ scrips/
|   â”œâ”€â”€ ğŸ Preparacion_com_ambiente.ipynb    # Create Schema, Tables, External location
â”œâ”€â”€ ğŸ“‚ seguridad/
|   â”œâ”€â”€ ğŸ Seguridad/permisos_external_invite_group.ipynb               # Sql Grant
â”œâ”€â”€ ğŸ“‚ reversion/
|   â”œâ”€â”€ ğŸ reversion/revoke_external_invite_group.ipynb               # Revoke permissions
â”œâ”€â”€ ğŸ“‚ dashboards/                 # dashboards/Ingresos Comercial Por Medios Digitales.lvdash.json dashboards/Ingresos_Digitales.jpg 
â””â”€â”€ ğŸ“„ README.md
```

---

## ğŸ› ï¸ TecnologÃ­as

<div align="center">

| TecnologÃ­a | PropÃ³sito |
|:----------:|:----------|
| ![Databricks](https://img.shields.io/badge/Azure_Databricks-FF3621?style=flat-square&logo=databricks&logoColor=white) | Motor de procesamiento distribuido Spark |
| ![Delta Lake](https://img.shields.io/badge/Delta_Lake-00ADD8?style=flat-square&logo=delta&logoColor=white) | Storage layer con ACID transactions |
| ![PySpark](https://img.shields.io/badge/PySpark-E25A1C?style=flat-square&logo=apache-spark&logoColor=white) | Framework de transformaciÃ³n de datos |
| ![ADLS](https://img.shields.io/badge/ADLS_Gen2-0078D4?style=flat-square&logo=microsoft-azure&logoColor=white) | Data Lake para almacenamiento persistente |
| ![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-2088FF?style=flat-square&logo=github-actions&logoColor=white) | AutomatizaciÃ³n CI/CD |
| ![Databricks Dashboards](https://img.shields.io/badge/Databricks Dashboards-F2C81?style=for-the-badge&logo=databricks&logoColor=black) |  VisualizaciÃ³n |

</div>

---

## âš™ï¸ Requisitos Previos

- â˜ï¸ Cuenta de Azure con acceso a Databricks
- â˜ï¸ Servicio azure sql Database
- ğŸ’» Workspace de Databricks configurado
- ğŸ–¥ï¸ Cluster activo (nombre: `Cluster1`)
- ğŸ™ Cuenta de GitHub con permisos de administrador
- ğŸ“¦ Azure Data Lake Storage Gen2 configurado
- ğŸ“Š Power BI Desktop (opcional para visualizaciÃ³n)

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1ï¸âƒ£ Clonar el Repositorio

```bash
git clone https://github.com/JohanSV83/CICDIGICOM01.git
cd CICDIGICOM01
```

### 2ï¸âƒ£ Configurar Databricks Token

1. Ir a Databricks Workspace
2. **User Settings** â†’ **Developer** â†’ **Access Tokens**
3. Click en **Generate New Token**
4. Configurar:
   - **Comment**: `GitHub CI/CD`
   - **Lifetime**: `90 days`
5. âš ï¸ Copiar y guardar el token

### 3ï¸âƒ£ Configurar GitHub Secrets

En tu repositorio: **Settings** â†’ **Secrets and variables** â†’ **Actions**

| Secret Name | Valor Ejemplo |
|------------|---------------|
| `DATABRICKS_HOST` | `https://adb-xxxxx.azuredatabricks.net` |
| `DATABRICKS_TOKEN` | `dapi_xxxxxxxxxxxxxxxx` |

### 4ï¸âƒ£ Tener conexion a origen al servicio  AZURE SQL DATABASE developer

```Notebook
conexion a azure sql database con las credenciales del servicio como :
servidor : srv-datacom.database.windows.net
enpoint
driver='com.microsoft.sqlserver.jdbc.SQLServerDriver'
database : db-datacom
puerto : ****
password :****
username:sqladmin
servername='srv-datacom.database.windows.net'
databasename='db-datacom'
```

<div align="center">

âœ… **Â¡ConfiguraciÃ³n completa!**

</div>

---

## ğŸ’» Uso

### ğŸ”„ Despliegue AutomÃ¡tico (Recomendado)

```bash
git add .
git commit -m "âœ¨ feat: mejoras en pipeline"
git push origin master
```

**GitHub Actions ejecutarÃ¡**:
- ğŸ“¤ Deploy de notebooks a `/proyecto_digicom`
- ğŸ”§ CreaciÃ³n del workflow `WF_ADB`
- â–¶ï¸ EjecuciÃ³n completa:  Bronze â†’ Silver â†’ Gold
- ğŸ“§ Notificaciones de resultados



### ğŸ”§ EjecuciÃ³n Local en Databricks

Navegar a `/Production/ETL-APPLE` y ejecutar en orden:

```
- Preparacion_com_ambiente.py         â†’ Crear esquema , esquemas, tablas y eliminacion de parquets de cada datalake bronze, silver y golden
- ingestion_com_data.py                â†’ Bronze Layer
- cleaning_com_data.py                   â†’ Silver Layer
- transform_com_data.py                   â†’ Silver Layer
- procesos/kpi_com_data.py                   â†’ Golden Layer

```

---


## ğŸ”„ CI/CD

### Pipeline de GitHub Actions

```yaml
Workflow: Deploy ETL Apple Sales And Warranty
â”œâ”€â”€ Deploy notebooks â†’ /Production/ETL-APPLE
â”œâ”€â”€ Eliminar workflow antiguo (si existe)
â”œâ”€â”€ Buscar cluster configurado
â”œâ”€â”€ Crear nuevo workflow con 5 tareas
â”œâ”€â”€ Ejecutar pipeline automÃ¡ticamente
â””â”€â”€ Monitorear y notificar resultados
```

### ğŸ”„  Workflow Databricks
![Texto descriptivo](CICDGICOM.png)
```
â° Schedule: on demand AM (Lima)
 ğŸ”’ Max concurrent runs: 1
â° Notificaciones: 
      success: johanvillano83@gmail.com
      failed:  johanvillano83@gmail.com
```

---

## ğŸ“ˆ Dashboards
https://github.com/JohanSV83/CICDIGICOM01/tree/main/dashboards

## ğŸ” Monitoreo

### En Databricks

**Workflows**:
- Ir a **Workflows** en el menÃº lateral
- Buscar `WF_ADB`
- Ver historial de ejecuciones

**Logs por Tarea**:
- Click en una ejecuciÃ³n especÃ­fica
- Click en cada tarea para ver logs detallados
- Revisar stdout/stderr en caso de errores

### En GitHub Actions

- Tab **Actions** del repositorio
- Ver historial de workflows
- Click en ejecuciÃ³n especÃ­fica para detalles
- Revisar logs de cada step

---

## ğŸ‘¤ Autor

<div align="center">

### Johan Hernan Sanchez Villano

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/johan-hernan-sanchez-villano-a4082492/)
[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/JohanSV83)
[![Email](https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:isc.johanvillano83@gmail.com)

**Data Engineering** | **Azure Databricks** | **Delta Lake** | **CI/CD**

</div>

---

copyrigth JOHAN HERNAN SANCHEZ VILLANO
---

<div align="center">

**Proyecto**: Data Engineering - Arquitectura Medallion  
**TecnologÃ­a**: Azure Databricks + Delta Lake + CI/CD  
**Ãšltima actualizaciÃ³n**: 2026


</div>
